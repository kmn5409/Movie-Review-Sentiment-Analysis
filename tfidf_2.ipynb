{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenize = TweetTokenizer().tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "sub = pd.read_csv('sampleSubmission.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n",
      "['PhraseId', 'SentenceId', 'Phrase', 'Sentiment']\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(list(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = train['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = TfidfVectorizer().fit_transform(t for t in train['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "train_count = count_vector.fit_transform(train['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 15240)\n"
     ]
    }
   ],
   "source": [
    "print(train_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12857)\t1\n",
      "  (0, 8807)\t1\n",
      "  (0, 13681)\t1\n",
      "  (0, 593)\t1\n",
      "  (0, 9085)\t1\n",
      "  (0, 1879)\t1\n",
      "  (0, 602)\t1\n",
      "  (0, 9204)\t1\n",
      "  (0, 14888)\t2\n",
      "  (0, 12424)\t1\n",
      "  (0, 5595)\t1\n",
      "  (0, 529)\t1\n",
      "  (0, 5837)\t1\n",
      "  (0, 5323)\t2\n",
      "  (0, 5821)\t2\n",
      "  (0, 7217)\t2\n",
      "  (0, 14871)\t1\n",
      "  (0, 13503)\t1\n",
      "  (0, 288)\t1\n",
      "  (0, 13505)\t3\n",
      "  (0, 3490)\t1\n",
      "  (0, 4577)\t1\n",
      "  (0, 9227)\t4\n",
      "  (0, 11837)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_count[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8791"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.vocabulary_.get(u'movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '10',\n",
       " '100',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '112',\n",
       " '12',\n",
       " '120',\n",
       " '127',\n",
       " '129',\n",
       " '12th',\n",
       " '13',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '146',\n",
       " '15',\n",
       " '15th',\n",
       " '16',\n",
       " '163',\n",
       " '168',\n",
       " '170',\n",
       " '1790',\n",
       " '18',\n",
       " '1899',\n",
       " '19',\n",
       " '1915',\n",
       " '1920',\n",
       " '1930s',\n",
       " '1933',\n",
       " '1937',\n",
       " '1938',\n",
       " '1940s',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1952',\n",
       " '1953',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1962',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1975',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1984',\n",
       " '1986',\n",
       " '1987',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '20',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '20th',\n",
       " '21',\n",
       " '21st',\n",
       " '22',\n",
       " '24',\n",
       " '2455',\n",
       " '25',\n",
       " '26',\n",
       " '270',\n",
       " '295',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30s',\n",
       " '37',\n",
       " '3d',\n",
       " '40',\n",
       " '40s',\n",
       " '42',\n",
       " '451',\n",
       " '48',\n",
       " '4ever',\n",
       " '4th',\n",
       " '4w',\n",
       " '50',\n",
       " '500',\n",
       " '50s',\n",
       " '51',\n",
       " '51st',\n",
       " '52',\n",
       " '53',\n",
       " '5ths',\n",
       " '60',\n",
       " '60s',\n",
       " '65',\n",
       " '65th',\n",
       " '66',\n",
       " '70',\n",
       " '70s',\n",
       " '71',\n",
       " '72',\n",
       " '75',\n",
       " '77',\n",
       " '78',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '80s',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '8th',\n",
       " '90',\n",
       " '90s',\n",
       " '91',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '98',\n",
       " '99',\n",
       " 'aaa',\n",
       " 'aaliyah',\n",
       " 'aan',\n",
       " 'abagnale',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbass',\n",
       " 'abbott',\n",
       " 'abbreviated',\n",
       " 'abc',\n",
       " 'abderrahmane',\n",
       " 'abdul',\n",
       " 'abel',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abiding',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abomination',\n",
       " 'aboriginal',\n",
       " 'aborted',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abrahams',\n",
       " 'abrasive',\n",
       " 'abridged',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuating',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accommodate',\n",
       " 'accomodates',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'ace',\n",
       " 'acerbic',\n",
       " 'ache',\n",
       " 'achero',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'achival',\n",
       " 'achronological',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acidity',\n",
       " 'ackerman',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acolytes',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activism',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actorish',\n",
       " 'actorliness',\n",
       " 'actorly',\n",
       " 'actors',\n",
       " 'actory',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actuary',\n",
       " 'acumen',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adams',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherents',\n",
       " 'adhering',\n",
       " 'adjective',\n",
       " 'adjusting',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'ado',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adopts',\n",
       " 'adorability',\n",
       " 'adorable',\n",
       " 'adorably',\n",
       " 'adored',\n",
       " 'adoring',\n",
       " 'adorns',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalized',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adrift',\n",
       " 'adroit',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adultery',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventues',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversity',\n",
       " 'advert',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advises',\n",
       " 'advocacy',\n",
       " 'aerial',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affectingly',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affects',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmational',\n",
       " 'affirming',\n",
       " 'affirms',\n",
       " 'affleck',\n",
       " 'afflicts',\n",
       " 'affluence',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affords',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'after',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterschool',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agape',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'agers',\n",
       " 'ages',\n",
       " 'agey',\n",
       " 'aggrandizing',\n",
       " 'aggravating',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressiveness',\n",
       " 'aggrieved',\n",
       " 'agile',\n",
       " 'aging',\n",
       " 'agitator',\n",
       " 'agitprop',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agreeably',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'aground',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahola',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aids',\n",
       " 'aiello',\n",
       " 'ailments',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aimlessness',\n",
       " 'aims',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airhead',\n",
       " 'airless',\n",
       " 'airs',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alacrity',\n",
       " 'aladdin',\n",
       " 'alagna',\n",
       " 'alain',\n",
       " 'alan',\n",
       " 'alarming',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcatraz',\n",
       " 'alchemical',\n",
       " 'aldrich',\n",
       " 'aleck',\n",
       " 'alert',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allied',\n",
       " 'allison',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluring',\n",
       " 'allusions',\n",
       " 'ally',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amalgam',\n",
       " 'amari',\n",
       " 'amaro',\n",
       " 'amassed',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amaze',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'ambience',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambitiously',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'amble',\n",
       " 'ambrose',\n",
       " 'amc',\n",
       " 'ame',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanized',\n",
       " 'americans',\n",
       " 'amiable',\n",
       " 'amiably',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amini',\n",
       " 'amir',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'among',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amorous',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amours',\n",
       " 'amp',\n",
       " 'ample',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusedly',\n",
       " 'amusement',\n",
       " 'amusements',\n",
       " 'amuses',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anachronistic',\n",
       " 'anakin',\n",
       " 'analgesic',\n",
       " 'analysis',\n",
       " 'analytical',\n",
       " 'analyze',\n",
       " 'anarchic',\n",
       " 'anarchist',\n",
       " 'anarchists',\n",
       " 'anarchy',\n",
       " 'anatomical',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'anchoring',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'anciently',\n",
       " 'ancillary',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andie',\n",
       " 'andrei',\n",
       " 'android',\n",
       " 'anecdote',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelina',\n",
       " 'angelique',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'angling',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anguish',\n",
       " 'anguished',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animations',\n",
       " 'animaton',\n",
       " 'animator',\n",
       " 'animatronic',\n",
       " 'anime',\n",
       " 'aniston',\n",
       " 'ankle',\n",
       " 'anna',\n",
       " 'annals',\n",
       " 'anne',\n",
       " 'annex',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'annoyance',\n",
       " 'annoyances',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'anomaly',\n",
       " 'anomie',\n",
       " 'anonymity',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'antagonism',\n",
       " 'ante',\n",
       " 'anteing',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anthropology',\n",
       " 'anthropomorphic',\n",
       " 'anti',\n",
       " 'antic',\n",
       " 'anticipated',\n",
       " 'anticipation',\n",
       " 'antics',\n",
       " 'antidote',\n",
       " 'antique',\n",
       " 'antiseptic',\n",
       " 'antitrust',\n",
       " 'anton',\n",
       " 'antonia',\n",
       " 'antonio',\n",
       " 'ants',\n",
       " 'antsy',\n",
       " 'antwone',\n",
       " 'anxieties',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'apartments',\n",
       " 'ape',\n",
       " 'apes',\n",
       " 'apex',\n",
       " 'aplenty',\n",
       " 'aplomb',\n",
       " 'apocalypse',\n",
       " 'apollo',\n",
       " 'apology',\n",
       " 'appalling',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appealingly',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appetite',\n",
       " 'appetites',\n",
       " 'appetizer',\n",
       " 'appetizing',\n",
       " 'applauded',\n",
       " 'apple',\n",
       " 'applegate',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointed',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'appropriately',\n",
       " 'approximation',\n",
       " 'april',\n",
       " 'apted',\n",
       " 'aptitude',\n",
       " 'aptly',\n",
       " 'aragorn',\n",
       " 'aranda',\n",
       " 'ararat',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'arcane',\n",
       " 'arch',\n",
       " 'archetypal',\n",
       " 'archibald',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'archival',\n",
       " 'archive',\n",
       " 'archives',\n",
       " 'archly',\n",
       " 'arctic',\n",
       " 'ardent',\n",
       " 'ardently',\n",
       " 'ardor',\n",
       " 'arduous',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'argentine',\n",
       " 'argentinean',\n",
       " 'argentinian',\n",
       " 'argento',\n",
       " 'argot',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argues',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arise',\n",
       " 'arising',\n",
       " 'aristocracy',\n",
       " 'aristocrat',\n",
       " 'aristocrats',\n",
       " 'arithmetic',\n",
       " 'ark',\n",
       " 'arkansas',\n",
       " 'arliss',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armchair',\n",
       " 'armed',\n",
       " 'armenia',\n",
       " 'armenian',\n",
       " 'armenians',\n",
       " 'arms',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arrangements',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arresting',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'artefact',\n",
       " 'arteta',\n",
       " 'artful',\n",
       " 'artfully',\n",
       " 'arthouse',\n",
       " 'arthur',\n",
       " 'articulate',\n",
       " 'articulates',\n",
       " 'artifice',\n",
       " 'artificial',\n",
       " 'artificiality',\n",
       " 'artist',\n",
       " 'artistes',\n",
       " 'artistic',\n",
       " 'artistically',\n",
       " 'artistry',\n",
       " 'artists',\n",
       " 'artless',\n",
       " 'artnering',\n",
       " 'arts',\n",
       " 'artsploitation',\n",
       " 'artsy',\n",
       " 'artwork',\n",
       " 'artworks',\n",
       " 'arty',\n",
       " 'arwen',\n",
       " 'as',\n",
       " 'ascends',\n",
       " 'ascension',\n",
       " 'ascertain',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asiaphiles',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asparagus',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphalt',\n",
       " 'aspiration',\n",
       " 'aspirations',\n",
       " 'aspire',\n",
       " 'aspired',\n",
       " 'aspires',\n",
       " 'asquith',\n",
       " 'assailants',\n",
       " 'assassin',\n",
       " 'assassination',\n",
       " 'assassins',\n",
       " 'assault',\n",
       " 'assaultive',\n",
       " 'assaults',\n",
       " 'assayas',\n",
       " 'assed',\n",
       " 'assembled',\n",
       " 'assembles',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'assess',\n",
       " 'assesses',\n",
       " 'asset',\n",
       " 'assets',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assimilated',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'assures',\n",
       " 'astonish',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'astounds',\n",
       " 'astray',\n",
       " 'astringent',\n",
       " 'astronaut',\n",
       " 'astronauts',\n",
       " 'astronomically',\n",
       " 'astute',\n",
       " 'asylum',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'athlete',\n",
       " 'athletes',\n",
       " 'athletic',\n",
       " 'athleticism',\n",
       " 'athon',\n",
       " 'atlantic',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atmospherics',\n",
       " 'atop',\n",
       " 'atrocious',\n",
       " 'atrociously',\n",
       " 'atrocities',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attackers',\n",
       " 'attacks',\n",
       " 'attal',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attendant',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attentions',\n",
       " 'attentive',\n",
       " 'attics',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attract',\n",
       " 'attracting',\n",
       " 'attraction',\n",
       " 'attractions',\n",
       " 'attractive',\n",
       " 'attracts',\n",
       " 'attributable',\n",
       " 'attuned',\n",
       " 'atypically',\n",
       " 'audacious',\n",
       " 'audacity',\n",
       " 'audiard',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'auditorium',\n",
       " 'audrey',\n",
       " 'augmented',\n",
       " 'august',\n",
       " 'augustine',\n",
       " 'augustinian',\n",
       " 'aurelie',\n",
       " 'auschwitz',\n",
       " 'auspicious',\n",
       " 'aussie',\n",
       " 'austen',\n",
       " 'austere',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austrian',\n",
       " 'auteil',\n",
       " 'auteuil',\n",
       " 'auteur',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'authenticate',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tf = tf_transformer.transform(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tfidf = tfidf_transformer.fit_transform(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False) : [0.50993836 0.50995143]\n",
      "\n",
      "\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) : [0.58038472 0.57417114]\n",
      "\n",
      "\n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) : [0.55471543 0.55223058]\n",
      "\n",
      "\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) : [0.57780882 0.57732382]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CV = 2\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    accuracy = cross_val_score(model,train_tfidf,train['Sentiment'],\\\n",
    "                            scoring='accuracy',cv=CV)\n",
    "    print(str(model),\":\",accuracy)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classf  =  MNB().fit(train_tfidf , train['Sentiment'])\n",
    "LSVC = LinearSVC().fit(train_tfidf, train['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_counts = count_vector.transform(test['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tfidf = tfidf_transformer.transform(test_counts)\n",
    "#X = TfidfVectorizer().fit_transform(t for t in X_train['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = classf.predict(test_tfidf)\n",
    "predicted_LSVC = LSVC.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Sentiment_Naive_Bayes2.csv', 'w') as csvfile:\n",
    "    csvfile.write('PhraseId,Sentiment\\n')\n",
    "    for i,j in zip(test['PhraseId'],predicted):\n",
    "        csvfile.write('{}, {}\\n'.format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Sentiment_LSVC.csv', 'w') as csvfile:\n",
    "    csvfile.write('PhraseId,Sentiment\\n')\n",
    "    for i,j in zip(test['PhraseId'],predicted_LSVC):\n",
    "        csvfile.write('{}, {}\\n'.format(i, j))\n",
    "#Score 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arraytotext(records):\n",
    "    return [\" \".join(record).lower() for record in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
       " 'A series of escapades demonstrating the adage that what is good for the goose',\n",
       " 'A series',\n",
       " 'A',\n",
       " 'series',\n",
       " 'of escapades demonstrating the adage that what is good for the goose',\n",
       " 'of',\n",
       " 'escapades demonstrating the adage that what is good for the goose',\n",
       " 'escapades',\n",
       " 'demonstrating the adage that what is good for the goose',\n",
       " 'demonstrating the adage',\n",
       " 'demonstrating',\n",
       " 'the adage',\n",
       " 'the',\n",
       " 'adage',\n",
       " 'that what is good for the goose',\n",
       " 'that',\n",
       " 'what is good for the goose',\n",
       " 'what',\n",
       " 'is good for the goose',\n",
       " 'is',\n",
       " 'good for the goose',\n",
       " 'good',\n",
       " 'for the goose',\n",
       " 'for',\n",
       " 'the goose',\n",
       " 'goose',\n",
       " 'is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
       " 'is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story',\n",
       " 'is also',\n",
       " 'also',\n",
       " 'good for the gander , some of which occasionally amuses but none of which amounts to much of a story',\n",
       " 'for the gander , some of which occasionally amuses but none of which amounts to much of a story',\n",
       " 'the gander , some of which occasionally amuses but none of which amounts to much of a story',\n",
       " 'the gander ,',\n",
       " 'the gander',\n",
       " 'gander',\n",
       " ',',\n",
       " 'some of which occasionally amuses but none of which amounts to much of a story',\n",
       " 'some of which',\n",
       " 'some',\n",
       " 'of which',\n",
       " 'which',\n",
       " 'occasionally amuses but none of which amounts to much of a story',\n",
       " 'occasionally',\n",
       " 'amuses but none of which amounts to much of a story',\n",
       " 'amuses',\n",
       " 'but none of which amounts to much of a story',\n",
       " 'but',\n",
       " 'none of which amounts to much of a story',\n",
       " 'none',\n",
       " 'of which amounts to much of a story',\n",
       " 'which amounts to much of a story',\n",
       " 'amounts to much of a story',\n",
       " 'amounts',\n",
       " 'to much of a story',\n",
       " 'to',\n",
       " 'much of a story',\n",
       " 'much',\n",
       " 'of a story',\n",
       " 'a story',\n",
       " 'story',\n",
       " '.',\n",
       " 'This quiet , introspective and entertaining independent is worth seeking .',\n",
       " 'This quiet , introspective and entertaining independent',\n",
       " 'This',\n",
       " 'quiet , introspective and entertaining independent',\n",
       " 'quiet , introspective and entertaining',\n",
       " 'quiet',\n",
       " ', introspective and entertaining',\n",
       " 'introspective and entertaining',\n",
       " 'introspective and',\n",
       " 'introspective',\n",
       " 'and',\n",
       " 'entertaining',\n",
       " 'independent',\n",
       " 'is worth seeking .',\n",
       " 'is worth seeking',\n",
       " 'is worth',\n",
       " 'worth',\n",
       " 'seeking',\n",
       " \"Even fans of Ismail Merchant 's work , I suspect , would have a hard time sitting through this one .\",\n",
       " \"Even fans of Ismail Merchant 's work\",\n",
       " 'Even fans',\n",
       " 'Even',\n",
       " 'fans',\n",
       " \"of Ismail Merchant 's work\",\n",
       " \"Ismail Merchant 's work\",\n",
       " \"Ismail Merchant 's\",\n",
       " 'Ismail',\n",
       " \"Merchant 's\",\n",
       " 'Merchant',\n",
       " \"'s\",\n",
       " 'work',\n",
       " ', I suspect , would have a hard time sitting through this one .',\n",
       " ', I suspect ,',\n",
       " 'I suspect ,',\n",
       " 'I suspect',\n",
       " 'I',\n",
       " 'suspect',\n",
       " 'would have a hard time sitting through this one .',\n",
       " 'would have a hard time sitting through this one',\n",
       " 'would',\n",
       " 'have a hard time sitting through this one',\n",
       " 'have',\n",
       " 'a hard time sitting through this one',\n",
       " 'a hard time',\n",
       " 'hard time',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'sitting through this one',\n",
       " 'sitting',\n",
       " 'through this one',\n",
       " 'through',\n",
       " 'this one',\n",
       " 'one',\n",
       " 'A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder of a Shakespearean tragedy or a juicy soap opera .',\n",
       " 'A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder of a Shakespearean tragedy or a juicy soap opera',\n",
       " 'A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder',\n",
       " 'A positively thrilling combination',\n",
       " 'positively thrilling combination',\n",
       " 'positively',\n",
       " 'thrilling combination',\n",
       " 'thrilling',\n",
       " 'combination',\n",
       " 'of ethnography and all the intrigue , betrayal , deceit and murder',\n",
       " 'ethnography and all the intrigue , betrayal , deceit and murder',\n",
       " 'ethnography and',\n",
       " 'ethnography',\n",
       " 'all the intrigue , betrayal , deceit and murder',\n",
       " 'all',\n",
       " 'the intrigue , betrayal , deceit and murder',\n",
       " 'intrigue , betrayal , deceit and murder',\n",
       " 'intrigue',\n",
       " ', betrayal , deceit and murder',\n",
       " 'betrayal , deceit and murder',\n",
       " 'betrayal',\n",
       " ', deceit and murder',\n",
       " 'deceit and murder',\n",
       " 'deceit and',\n",
       " 'deceit',\n",
       " 'murder',\n",
       " 'of a Shakespearean tragedy or a juicy soap opera',\n",
       " 'a Shakespearean tragedy or a juicy soap opera',\n",
       " 'a Shakespearean tragedy or',\n",
       " 'a Shakespearean tragedy',\n",
       " 'Shakespearean tragedy',\n",
       " 'Shakespearean',\n",
       " 'tragedy',\n",
       " 'or',\n",
       " 'a juicy soap opera',\n",
       " 'juicy soap opera',\n",
       " 'juicy',\n",
       " 'soap opera',\n",
       " 'soap',\n",
       " 'opera',\n",
       " 'Aggressive self-glorification and a manipulative whitewash .',\n",
       " 'Aggressive self-glorification and a manipulative whitewash',\n",
       " 'Aggressive',\n",
       " 'self-glorification and a manipulative whitewash',\n",
       " 'self-glorification and',\n",
       " 'self-glorification',\n",
       " 'a manipulative whitewash',\n",
       " 'manipulative whitewash',\n",
       " 'manipulative',\n",
       " 'whitewash',\n",
       " 'A comedy-drama of nearly epic proportions rooted in a sincere performance by the title character undergoing midlife crisis .',\n",
       " 'A comedy-drama of nearly epic proportions',\n",
       " 'A comedy-drama',\n",
       " 'comedy-drama',\n",
       " 'of nearly epic proportions',\n",
       " 'nearly epic proportions',\n",
       " 'nearly epic',\n",
       " 'nearly',\n",
       " 'epic',\n",
       " 'proportions',\n",
       " 'rooted in a sincere performance by the title character undergoing midlife crisis .',\n",
       " 'rooted in a sincere performance by the title character undergoing midlife crisis',\n",
       " 'rooted in a sincere performance',\n",
       " 'rooted',\n",
       " 'in a sincere performance',\n",
       " 'in',\n",
       " 'a sincere performance',\n",
       " 'sincere performance',\n",
       " 'sincere',\n",
       " 'performance',\n",
       " 'by the title character undergoing midlife crisis',\n",
       " 'by',\n",
       " 'the title character undergoing midlife crisis',\n",
       " 'the title character',\n",
       " 'title character',\n",
       " 'title',\n",
       " 'character',\n",
       " 'undergoing midlife crisis',\n",
       " 'undergoing',\n",
       " 'midlife crisis',\n",
       " 'midlife',\n",
       " 'crisis',\n",
       " 'Narratively , Trouble Every Day is a plodding mess .',\n",
       " 'Narratively',\n",
       " ', Trouble Every Day is a plodding mess .',\n",
       " 'Trouble Every Day is a plodding mess .',\n",
       " 'Trouble Every Day',\n",
       " 'Trouble',\n",
       " 'Every Day',\n",
       " 'Every',\n",
       " 'Day',\n",
       " 'is a plodding mess .',\n",
       " 'is a plodding mess',\n",
       " 'a plodding mess',\n",
       " 'plodding mess',\n",
       " 'plodding',\n",
       " 'mess',\n",
       " \"The Importance of Being Earnest , so thick with wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'The Importance',\n",
       " 'Importance',\n",
       " \"of Being Earnest , so thick with wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " \"Being Earnest , so thick with wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'Being',\n",
       " \"Earnest , so thick with wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'Earnest ,',\n",
       " 'Earnest',\n",
       " \"so thick with wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'so',\n",
       " \"thick with wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'thick',\n",
       " \"with wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'with',\n",
       " \"wit it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'wit',\n",
       " \"it plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'it',\n",
       " \"plays like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'plays',\n",
       " \"like a reading from Bartlett 's Familiar Quotations\",\n",
       " 'like',\n",
       " \"a reading from Bartlett 's Familiar Quotations\",\n",
       " 'a reading',\n",
       " 'reading',\n",
       " \"from Bartlett 's Familiar Quotations\",\n",
       " 'from',\n",
       " \"Bartlett 's Familiar Quotations\",\n",
       " \"Bartlett 's\",\n",
       " 'Bartlett',\n",
       " 'Familiar Quotations',\n",
       " 'Familiar',\n",
       " 'Quotations',\n",
       " \"But it does n't leave you with much .\",\n",
       " \"it does n't leave you with much .\",\n",
       " \"does n't leave you with much .\",\n",
       " \"does n't leave you with much\",\n",
       " \"does n't\",\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'leave you with much',\n",
       " 'leave you',\n",
       " 'leave',\n",
       " 'you',\n",
       " 'with much',\n",
       " 'You could hate it for the same reason .',\n",
       " 'could hate it for the same reason .',\n",
       " 'could hate it for the same reason',\n",
       " 'could',\n",
       " 'hate it for the same reason',\n",
       " 'hate it',\n",
       " 'hate',\n",
       " 'for the same reason',\n",
       " 'the same reason',\n",
       " 'same reason',\n",
       " 'same',\n",
       " 'reason',\n",
       " \"There 's little to recommend Snow Dogs , unless one considers cliched dialogue and perverse escapism a source of high hilarity .\",\n",
       " 'There',\n",
       " \"'s little to recommend Snow Dogs , unless one considers cliched dialogue and perverse escapism a source of high hilarity .\",\n",
       " \"'s little to recommend Snow Dogs , unless one considers cliched dialogue and perverse escapism a source of high hilarity\",\n",
       " \"'s little to recommend Snow Dogs ,\",\n",
       " \"'s little to recommend Snow Dogs\",\n",
       " 'little to recommend Snow Dogs',\n",
       " 'little',\n",
       " 'to recommend Snow Dogs',\n",
       " 'recommend Snow Dogs',\n",
       " 'recommend',\n",
       " 'Snow Dogs',\n",
       " 'Snow',\n",
       " 'Dogs',\n",
       " 'unless one considers cliched dialogue and perverse escapism a source of high hilarity',\n",
       " 'unless',\n",
       " 'one considers cliched dialogue and perverse escapism a source of high hilarity',\n",
       " 'considers cliched dialogue and perverse escapism a source of high hilarity',\n",
       " 'considers',\n",
       " 'cliched dialogue and perverse escapism a source of high hilarity',\n",
       " 'cliched dialogue and perverse escapism',\n",
       " 'cliched dialogue and',\n",
       " 'cliched dialogue',\n",
       " 'cliched',\n",
       " 'dialogue',\n",
       " 'perverse escapism',\n",
       " 'perverse',\n",
       " 'escapism',\n",
       " 'a source of high hilarity',\n",
       " 'a source',\n",
       " 'source',\n",
       " 'of high hilarity',\n",
       " 'high hilarity',\n",
       " 'high',\n",
       " 'hilarity',\n",
       " \"Kung Pow is Oedekerk 's realization of his childhood dream to be in a martial-arts flick , and proves that sometimes the dreams of youth should remain just that .\",\n",
       " 'Kung Pow',\n",
       " 'Kung',\n",
       " 'Pow',\n",
       " \"is Oedekerk 's realization of his childhood dream to be in a martial-arts flick , and proves that sometimes the dreams of youth should remain just that .\",\n",
       " \"is Oedekerk 's realization of his childhood dream to be in a martial-arts flick , and proves that sometimes the dreams of youth should remain just that\",\n",
       " \"is Oedekerk 's realization of his childhood dream to be in a martial-arts flick , and\",\n",
       " \"is Oedekerk 's realization of his childhood dream to be in a martial-arts flick ,\",\n",
       " \"is Oedekerk 's realization of his childhood dream to be in a martial-arts flick\",\n",
       " \"Oedekerk 's realization of his childhood dream to be in a martial-arts flick\",\n",
       " \"Oedekerk 's realization of his childhood dream\",\n",
       " \"Oedekerk 's realization\",\n",
       " \"Oedekerk 's\",\n",
       " 'Oedekerk',\n",
       " 'realization',\n",
       " 'of his childhood dream',\n",
       " 'his childhood dream',\n",
       " 'his',\n",
       " 'childhood dream',\n",
       " 'childhood',\n",
       " 'dream',\n",
       " 'to be in a martial-arts flick',\n",
       " 'be in a martial-arts flick',\n",
       " 'be',\n",
       " 'in a martial-arts flick',\n",
       " 'a martial-arts flick',\n",
       " 'martial-arts flick',\n",
       " 'martial-arts',\n",
       " 'flick',\n",
       " 'proves that sometimes the dreams of youth should remain just that',\n",
       " 'proves',\n",
       " 'that sometimes the dreams of youth should remain just that',\n",
       " 'sometimes the dreams of youth should remain just that',\n",
       " 'sometimes',\n",
       " 'the dreams of youth should remain just that',\n",
       " 'the dreams of youth',\n",
       " 'the dreams',\n",
       " 'dreams',\n",
       " 'of youth',\n",
       " 'youth',\n",
       " 'should remain just that',\n",
       " 'should',\n",
       " 'remain just that',\n",
       " 'remain',\n",
       " 'just that',\n",
       " 'just',\n",
       " 'The performances are an absolute joy .',\n",
       " 'The performances',\n",
       " 'performances',\n",
       " 'are an absolute joy .',\n",
       " 'are an absolute joy',\n",
       " 'are',\n",
       " 'an absolute joy',\n",
       " 'an',\n",
       " 'absolute joy',\n",
       " 'absolute',\n",
       " 'joy',\n",
       " 'Fresnadillo has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense .',\n",
       " 'Fresnadillo',\n",
       " 'has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense .',\n",
       " 'has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'has',\n",
       " 'something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'something',\n",
       " 'serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'serious',\n",
       " 'to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'say',\n",
       " 'about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'about',\n",
       " 'the ways in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'the ways',\n",
       " 'ways',\n",
       " 'in which extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'in which',\n",
       " 'extravagant chance can distort our perspective and throw us off the path of good sense',\n",
       " 'extravagant chance',\n",
       " 'extravagant',\n",
       " 'chance',\n",
       " 'can distort our perspective and throw us off the path of good sense',\n",
       " 'can',\n",
       " 'distort our perspective and throw us off the path of good sense',\n",
       " 'distort our perspective and',\n",
       " 'distort our perspective',\n",
       " 'distort',\n",
       " 'our perspective',\n",
       " 'our',\n",
       " 'perspective',\n",
       " 'throw us off the path of good sense',\n",
       " 'throw us',\n",
       " 'throw',\n",
       " 'us',\n",
       " 'off the path of good sense',\n",
       " 'off',\n",
       " 'the path of good sense',\n",
       " 'the path',\n",
       " 'path',\n",
       " 'of good sense',\n",
       " 'good sense',\n",
       " 'sense',\n",
       " 'I still like Moonlight Mile , better judgment be damned .',\n",
       " 'still like Moonlight Mile , better judgment be damned .',\n",
       " 'still',\n",
       " 'like Moonlight Mile , better judgment be damned .',\n",
       " 'like Moonlight Mile , better judgment be damned',\n",
       " 'Moonlight Mile , better judgment be damned',\n",
       " 'Moonlight Mile , better judgment',\n",
       " 'Moonlight',\n",
       " 'Mile , better judgment',\n",
       " 'Mile',\n",
       " ', better judgment',\n",
       " 'better judgment',\n",
       " 'better',\n",
       " 'judgment',\n",
       " 'be damned',\n",
       " 'damned',\n",
       " 'A welcome relief from baseball movies that try too hard to be mythic , this one is a sweet and modest and ultimately winning story .',\n",
       " 'A welcome relief from baseball movies that try too hard to be mythic',\n",
       " 'A welcome relief',\n",
       " 'welcome relief',\n",
       " 'welcome',\n",
       " 'relief',\n",
       " 'from baseball movies that try too hard to be mythic',\n",
       " 'baseball movies that try too hard to be mythic',\n",
       " 'baseball movies',\n",
       " 'baseball',\n",
       " 'movies',\n",
       " 'that try too hard to be mythic',\n",
       " 'try too hard to be mythic',\n",
       " 'try',\n",
       " 'too hard to be mythic',\n",
       " 'too',\n",
       " 'hard to be mythic',\n",
       " 'to be mythic',\n",
       " 'be mythic',\n",
       " 'mythic',\n",
       " ', this one is a sweet and modest and ultimately winning story .',\n",
       " 'this one is a sweet and modest and ultimately winning story .',\n",
       " 'is a sweet and modest and ultimately winning story .',\n",
       " 'is a sweet and modest and ultimately winning story',\n",
       " 'a sweet and modest and ultimately winning story',\n",
       " 'a sweet and modest and',\n",
       " 'a sweet and modest',\n",
       " 'sweet and modest',\n",
       " 'sweet and',\n",
       " 'sweet',\n",
       " 'modest',\n",
       " 'ultimately winning story',\n",
       " 'ultimately',\n",
       " 'winning story',\n",
       " 'winning',\n",
       " 'a bilingual charmer , just like the woman who inspired it',\n",
       " 'a bilingual charmer ,',\n",
       " 'a bilingual charmer',\n",
       " 'bilingual charmer',\n",
       " 'bilingual',\n",
       " 'charmer',\n",
       " 'just like the woman who inspired it',\n",
       " 'like the woman who inspired it',\n",
       " 'the woman who inspired it',\n",
       " 'the woman',\n",
       " 'woman',\n",
       " 'who inspired it',\n",
       " 'who',\n",
       " 'inspired it',\n",
       " 'inspired',\n",
       " \"Like a less dizzily gorgeous companion to Mr. Wong 's In the Mood for Love -- very much a Hong Kong movie despite its mainland setting .\",\n",
       " 'Like a less dizzily gorgeous companion to Mr.',\n",
       " 'a less dizzily gorgeous companion to Mr.',\n",
       " 'a less dizzily gorgeous companion',\n",
       " 'less dizzily gorgeous companion',\n",
       " 'less dizzily gorgeous',\n",
       " 'less',\n",
       " 'dizzily gorgeous',\n",
       " 'dizzily',\n",
       " 'gorgeous',\n",
       " 'companion',\n",
       " 'to Mr.',\n",
       " 'Mr.',\n",
       " \"Wong 's In the Mood for Love -- very much a Hong Kong movie despite its mainland setting .\",\n",
       " 'Wong',\n",
       " \"'s In the Mood for Love -- very much a Hong Kong movie despite its mainland setting .\",\n",
       " \"'s In the Mood for Love -- very much a Hong Kong movie despite its mainland setting\",\n",
       " \"'s In the Mood for Love -- very much a Hong Kong movie\",\n",
       " 'In the Mood for Love -- very much a Hong Kong movie',\n",
       " 'the Mood for Love -- very much a Hong Kong movie',\n",
       " 'the Mood',\n",
       " 'Mood',\n",
       " 'for Love -- very much a Hong Kong movie',\n",
       " 'Love -- very much a Hong Kong movie',\n",
       " 'Love -- very much',\n",
       " 'Love --',\n",
       " 'Love',\n",
       " '--',\n",
       " 'very much',\n",
       " 'very',\n",
       " 'a Hong Kong movie',\n",
       " 'Hong Kong movie',\n",
       " 'Hong',\n",
       " 'Kong movie',\n",
       " 'Kong',\n",
       " 'movie',\n",
       " 'despite its mainland setting',\n",
       " 'despite',\n",
       " 'its mainland setting',\n",
       " 'its',\n",
       " 'mainland setting',\n",
       " 'mainland',\n",
       " 'setting',\n",
       " 'As inept as big-screen remakes of The Avengers and The Wild Wild West .',\n",
       " 'As inept as big-screen remakes of The Avengers and The Wild Wild West',\n",
       " 'As inept',\n",
       " 'As',\n",
       " 'inept',\n",
       " 'as big-screen remakes of The Avengers and The Wild Wild West',\n",
       " 'big-screen remakes of The Avengers and The Wild Wild West',\n",
       " 'big-screen remakes',\n",
       " 'big-screen',\n",
       " 'remakes',\n",
       " 'of The Avengers and The Wild Wild West',\n",
       " 'The Avengers and The Wild Wild West',\n",
       " 'The Avengers and',\n",
       " 'The Avengers',\n",
       " 'Avengers',\n",
       " 'The Wild Wild West',\n",
       " 'Wild Wild West',\n",
       " 'Wild',\n",
       " 'Wild West',\n",
       " 'West',\n",
       " \"It 's everything you 'd expect -- but nothing more .\",\n",
       " \"'s everything you 'd expect -- but nothing more .\",\n",
       " \"'s everything you 'd expect -- but nothing more\",\n",
       " \"everything you 'd expect -- but nothing more\",\n",
       " 'everything',\n",
       " \"you 'd expect -- but nothing more\",\n",
       " \"'d expect -- but nothing more\",\n",
       " \"'d\",\n",
       " 'expect -- but nothing more',\n",
       " 'expect -- but nothing',\n",
       " 'expect --',\n",
       " 'expect',\n",
       " 'but nothing',\n",
       " 'nothing',\n",
       " 'more',\n",
       " 'Best indie of the year , so far .',\n",
       " 'Best',\n",
       " 'indie of the year , so far .',\n",
       " 'indie of the year , so far',\n",
       " 'indie of the year ,',\n",
       " 'indie of the year',\n",
       " 'indie',\n",
       " 'of the year',\n",
       " 'the year',\n",
       " 'year',\n",
       " 'so far',\n",
       " 'far',\n",
       " \"Hatfield and Hicks make the oddest of couples , and in this sense the movie becomes a study of the gambles of the publishing world , offering a case study that exists apart from all the movie 's political ramifications .\",\n",
       " \"Hatfield and Hicks make the oddest of couples , and in this sense the movie becomes a study of the gambles of the publishing world , offering a case study that exists apart from all the movie 's political ramifications\",\n",
       " 'Hatfield and Hicks make the oddest of couples , and',\n",
       " 'Hatfield and Hicks make the oddest of couples ,',\n",
       " 'Hatfield and Hicks make the oddest of couples',\n",
       " 'Hatfield and Hicks',\n",
       " 'Hatfield and',\n",
       " 'Hatfield',\n",
       " 'Hicks',\n",
       " 'make the oddest of couples',\n",
       " 'make',\n",
       " 'the oddest of couples',\n",
       " 'the oddest',\n",
       " 'oddest',\n",
       " 'of couples',\n",
       " 'couples',\n",
       " \"in this sense the movie becomes a study of the gambles of the publishing world , offering a case study that exists apart from all the movie 's political ramifications\",\n",
       " 'in this sense',\n",
       " 'this sense',\n",
       " \"the movie becomes a study of the gambles of the publishing world , offering a case study that exists apart from all the movie 's political ramifications\",\n",
       " 'the movie',\n",
       " \"becomes a study of the gambles of the publishing world , offering a case study that exists apart from all the movie 's political ramifications\",\n",
       " 'becomes a study of the gambles of the publishing world ,',\n",
       " 'becomes a study of the gambles of the publishing world',\n",
       " 'becomes',\n",
       " 'a study of the gambles of the publishing world',\n",
       " 'a study',\n",
       " 'study',\n",
       " 'of the gambles of the publishing world',\n",
       " 'the gambles of the publishing world',\n",
       " 'the gambles',\n",
       " 'gambles',\n",
       " 'of the publishing world',\n",
       " 'the publishing world',\n",
       " 'publishing world',\n",
       " 'publishing',\n",
       " 'world',\n",
       " \"offering a case study that exists apart from all the movie 's political ramifications\",\n",
       " 'offering',\n",
       " \"a case study that exists apart from all the movie 's political ramifications\",\n",
       " 'a case study',\n",
       " 'case study',\n",
       " 'case',\n",
       " \"that exists apart from all the movie 's political ramifications\",\n",
       " \"exists apart from all the movie 's political ramifications\",\n",
       " 'exists apart',\n",
       " 'exists',\n",
       " 'apart',\n",
       " \"from all the movie 's political ramifications\",\n",
       " \"all the movie 's political ramifications\",\n",
       " \"the movie 's political ramifications\",\n",
       " \"the movie 's\",\n",
       " \"movie 's\",\n",
       " 'political ramifications',\n",
       " 'political',\n",
       " 'ramifications',\n",
       " \"It 's like going to a house party and watching the host defend himself against a frothing ex-girlfriend .\",\n",
       " \"'s like going to a house party and watching the host defend himself against a frothing ex-girlfriend .\",\n",
       " \"'s like going to a house party and watching the host defend himself against a frothing ex-girlfriend\",\n",
       " 'like going to a house party and watching the host defend himself against a frothing ex-girlfriend',\n",
       " 'going to a house party and watching the host defend himself against a frothing ex-girlfriend',\n",
       " 'going to a house party and',\n",
       " 'going to a house party',\n",
       " 'going',\n",
       " 'to a house party',\n",
       " 'a house party',\n",
       " 'house party',\n",
       " 'house',\n",
       " 'party',\n",
       " 'watching the host defend himself against a frothing ex-girlfriend',\n",
       " 'watching',\n",
       " 'the host defend himself against a frothing ex-girlfriend',\n",
       " 'the host',\n",
       " 'host',\n",
       " 'defend himself against a frothing ex-girlfriend',\n",
       " 'defend himself',\n",
       " 'defend',\n",
       " 'himself',\n",
       " 'against a frothing ex-girlfriend',\n",
       " 'against',\n",
       " 'a frothing ex-girlfriend',\n",
       " 'frothing ex-girlfriend',\n",
       " 'frothing',\n",
       " 'ex-girlfriend',\n",
       " \"That the Chuck Norris `` grenade gag '' occurs about 7 times during Windtalkers is a good indication of how serious-minded the film is .\",\n",
       " \"That the Chuck Norris `` grenade gag ''\",\n",
       " \"the Chuck Norris `` grenade gag ''\",\n",
       " \"Chuck Norris `` grenade gag ''\",\n",
       " 'Chuck',\n",
       " \"Norris `` grenade gag ''\",\n",
       " 'Norris',\n",
       " \"`` grenade gag ''\",\n",
       " '``',\n",
       " \"grenade gag ''\",\n",
       " 'grenade',\n",
       " \"gag ''\",\n",
       " 'gag',\n",
       " \"''\",\n",
       " 'occurs about 7 times during Windtalkers is a good indication of how serious-minded the film is .',\n",
       " 'occurs about 7 times during Windtalkers is a good indication of how serious-minded the film is',\n",
       " 'occurs',\n",
       " 'about 7 times during Windtalkers is a good indication of how serious-minded the film is',\n",
       " 'about 7 times during Windtalkers',\n",
       " 'about 7 times',\n",
       " '7 times',\n",
       " '7',\n",
       " 'times',\n",
       " 'during Windtalkers',\n",
       " 'during',\n",
       " 'Windtalkers',\n",
       " 'is a good indication of how serious-minded the film is',\n",
       " 'a good indication of how serious-minded the film is',\n",
       " 'a good indication',\n",
       " 'good indication',\n",
       " 'indication',\n",
       " 'of how serious-minded the film is',\n",
       " 'how serious-minded the film is',\n",
       " 'how',\n",
       " 'serious-minded the film is',\n",
       " 'serious-minded the film',\n",
       " 'serious-minded',\n",
       " 'the film',\n",
       " 'film',\n",
       " 'The plot is romantic comedy boilerplate from start to finish .',\n",
       " 'The plot',\n",
       " 'plot',\n",
       " 'is romantic comedy boilerplate from start to finish .',\n",
       " 'is romantic comedy boilerplate from start to finish',\n",
       " 'romantic comedy boilerplate from start to finish',\n",
       " 'romantic comedy boilerplate from start',\n",
       " 'romantic comedy boilerplate',\n",
       " 'romantic',\n",
       " 'comedy boilerplate',\n",
       " 'comedy',\n",
       " 'boilerplate',\n",
       " 'from start',\n",
       " 'start',\n",
       " 'to finish',\n",
       " 'finish',\n",
       " 'It arrives with an impeccable pedigree , mongrel pep , and almost indecipherable plot complications .',\n",
       " 'arrives with an impeccable pedigree , mongrel pep , and almost indecipherable plot complications .',\n",
       " 'arrives with an impeccable pedigree , mongrel pep , and almost indecipherable plot complications',\n",
       " 'arrives',\n",
       " 'with an impeccable pedigree , mongrel pep , and almost indecipherable plot complications',\n",
       " 'an impeccable pedigree , mongrel pep , and almost indecipherable plot complications',\n",
       " 'an impeccable pedigree , mongrel pep , and almost',\n",
       " 'an impeccable pedigree , mongrel pep , and',\n",
       " 'an impeccable pedigree , mongrel pep ,',\n",
       " 'an impeccable pedigree , mongrel pep',\n",
       " 'impeccable pedigree , mongrel pep',\n",
       " 'impeccable',\n",
       " 'pedigree , mongrel pep',\n",
       " 'pedigree',\n",
       " ', mongrel pep',\n",
       " 'mongrel pep',\n",
       " 'mongrel',\n",
       " 'pep',\n",
       " 'almost',\n",
       " 'indecipherable plot complications',\n",
       " 'indecipherable',\n",
       " 'plot complications',\n",
       " 'complications',\n",
       " 'A film that clearly means to preach exclusively to the converted .',\n",
       " 'A film that clearly means to',\n",
       " 'A film',\n",
       " 'that clearly means to',\n",
       " 'clearly means to',\n",
       " 'clearly',\n",
       " 'means to',\n",
       " 'means',\n",
       " 'preach exclusively to the converted .',\n",
       " 'preach exclusively to the converted',\n",
       " 'preach exclusively',\n",
       " 'preach',\n",
       " 'exclusively',\n",
       " 'to the converted',\n",
       " 'the converted',\n",
       " 'converted',\n",
       " \"While The Importance of Being Earnest offers opportunities for occasional smiles and chuckles , it does n't give us a reason to be in the theater beyond Wilde 's wit and the actors ' performances .\",\n",
       " 'While The Importance of Being Earnest offers opportunities for occasional smiles and chuckles',\n",
       " 'While',\n",
       " 'The Importance of Being Earnest offers opportunities for occasional smiles and chuckles',\n",
       " 'The Importance of Being Earnest',\n",
       " 'of Being Earnest',\n",
       " 'Being Earnest',\n",
       " 'offers opportunities for occasional smiles and chuckles',\n",
       " 'offers opportunities for occasional smiles and',\n",
       " 'offers opportunities for occasional smiles',\n",
       " 'offers',\n",
       " 'opportunities for occasional smiles',\n",
       " 'opportunities',\n",
       " 'for occasional smiles',\n",
       " 'occasional smiles',\n",
       " 'occasional',\n",
       " 'smiles',\n",
       " 'chuckles',\n",
       " \", it does n't give us a reason to be in the theater beyond Wilde 's wit and the actors ' performances .\",\n",
       " \"it does n't give us a reason to be in the theater beyond Wilde 's wit and the actors ' performances .\",\n",
       " \"does n't give us a reason to be in the theater beyond Wilde 's wit and the actors ' performances .\",\n",
       " \"does n't give us a reason to be in the theater beyond Wilde 's wit and the actors ' performances\",\n",
       " \"give us a reason to be in the theater beyond Wilde 's wit and the actors ' performances\",\n",
       " 'give us',\n",
       " 'give',\n",
       " \"a reason to be in the theater beyond Wilde 's wit and the actors ' performances\",\n",
       " \"reason to be in the theater beyond Wilde 's wit and the actors ' performances\",\n",
       " \"to be in the theater beyond Wilde 's wit and the actors ' performances\",\n",
       " \"be in the theater beyond Wilde 's wit and the actors ' performances\",\n",
       " 'be in the theater',\n",
       " 'in the theater',\n",
       " 'the theater',\n",
       " 'theater',\n",
       " \"beyond Wilde 's wit and the actors ' performances\",\n",
       " 'beyond',\n",
       " \"Wilde 's wit and the actors ' performances\",\n",
       " \"Wilde 's wit and\",\n",
       " \"Wilde 's wit\",\n",
       " \"Wilde 's\",\n",
       " 'Wilde',\n",
       " \"the actors ' performances\",\n",
       " \"the actors '\",\n",
       " \"actors '\",\n",
       " 'actors',\n",
       " \"'\",\n",
       " \"The latest vapid actor 's exercise to appropriate the structure of Arthur Schnitzler 's Reigen .\",\n",
       " 'The latest',\n",
       " 'latest',\n",
       " \"vapid actor 's exercise to appropriate the structure of Arthur Schnitzler 's Reigen .\",\n",
       " \"vapid actor 's exercise to appropriate the structure of Arthur Schnitzler 's Reigen\",\n",
       " \"vapid actor 's exercise\",\n",
       " 'vapid',\n",
       " \"actor 's exercise\",\n",
       " \"actor 's\",\n",
       " 'actor',\n",
       " 'exercise',\n",
       " \"to appropriate the structure of Arthur Schnitzler 's Reigen\",\n",
       " \"appropriate the structure of Arthur Schnitzler 's Reigen\",\n",
       " 'appropriate the structure',\n",
       " 'appropriate',\n",
       " 'the structure',\n",
       " 'structure',\n",
       " \"of Arthur Schnitzler 's Reigen\",\n",
       " \"Arthur Schnitzler 's Reigen\",\n",
       " \"Arthur Schnitzler 's\",\n",
       " 'Arthur',\n",
       " \"Schnitzler 's\",\n",
       " 'Schnitzler',\n",
       " 'Reigen',\n",
       " \"More vaudeville show than well-constructed narrative , but on those terms it 's inoffensive and actually rather sweet .\",\n",
       " \"More vaudeville show than well-constructed narrative , but on those terms it 's inoffensive and actually rather sweet\",\n",
       " 'More vaudeville show than well-constructed narrative , but',\n",
       " 'More vaudeville show than well-constructed narrative ,',\n",
       " 'More vaudeville show than well-constructed narrative',\n",
       " 'More vaudeville',\n",
       " 'vaudeville',\n",
       " 'show than well-constructed narrative',\n",
       " 'show',\n",
       " 'than well-constructed narrative',\n",
       " 'than',\n",
       " 'well-constructed narrative',\n",
       " 'well-constructed',\n",
       " 'narrative',\n",
       " \"on those terms it 's inoffensive and actually rather sweet\",\n",
       " 'on those terms',\n",
       " 'on',\n",
       " 'those terms',\n",
       " 'those',\n",
       " 'terms',\n",
       " \"it 's inoffensive and actually rather sweet\",\n",
       " \"'s inoffensive and actually rather sweet\",\n",
       " 'inoffensive and actually rather sweet',\n",
       " 'inoffensive and actually',\n",
       " 'inoffensive and',\n",
       " 'inoffensive',\n",
       " 'actually',\n",
       " 'rather sweet',\n",
       " 'rather',\n",
       " 'Nothing more than a run-of-the-mill action flick .',\n",
       " 'more than a run-of-the-mill action flick .',\n",
       " 'more than a run-of-the-mill action',\n",
       " 'than a run-of-the-mill action',\n",
       " 'a run-of-the-mill action',\n",
       " 'run-of-the-mill action',\n",
       " 'run-of-the-mill',\n",
       " 'action',\n",
       " 'flick .',\n",
       " 'Hampered -- no , paralyzed -- by a self-indulgent script ... that aims for poetry and ends up sounding like satire .',\n",
       " 'Hampered -- no , paralyzed -- by a self-indulgent script ... that aims for poetry and ends up sounding like satire',\n",
       " 'Hampered -- no , paralyzed -- by a self-indulgent script ...',\n",
       " 'Hampered -- no , paralyzed -- by a self-indulgent script',\n",
       " 'Hampered -- no , paralyzed --',\n",
       " 'Hampered',\n",
       " '-- no , paralyzed --',\n",
       " 'no , paralyzed --',\n",
       " 'no , paralyzed',\n",
       " 'no',\n",
       " ', paralyzed',\n",
       " 'paralyzed',\n",
       " 'by a self-indulgent script',\n",
       " 'a self-indulgent script',\n",
       " 'self-indulgent script',\n",
       " 'self-indulgent',\n",
       " 'script',\n",
       " '...',\n",
       " 'that aims for poetry and ends up sounding like satire',\n",
       " 'aims for poetry and ends up sounding like satire',\n",
       " 'aims for poetry and',\n",
       " 'aims for poetry',\n",
       " 'aims',\n",
       " 'for poetry',\n",
       " 'poetry',\n",
       " 'ends up sounding like satire',\n",
       " 'ends up',\n",
       " 'ends',\n",
       " 'up',\n",
       " 'sounding like satire',\n",
       " 'sounding',\n",
       " 'like satire',\n",
       " 'satire',\n",
       " 'Ice Age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on .',\n",
       " 'Ice Age is the first computer-generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on',\n",
       " 'Ice Age is the first computer-generated feature cartoon to feel like other movies , and',\n",
       " 'Ice Age is the first computer-generated feature cartoon to feel like other movies ,',\n",
       " 'Ice Age is the first computer-generated feature cartoon to feel like other movies',\n",
       " 'Ice Age',\n",
       " 'Ice',\n",
       " 'Age',\n",
       " 'is the first computer-generated feature cartoon to feel like other movies',\n",
       " 'the first computer-generated feature cartoon to feel like other movies',\n",
       " 'the first computer-generated feature cartoon',\n",
       " 'first computer-generated feature cartoon',\n",
       " 'first',\n",
       " 'computer-generated feature cartoon',\n",
       " 'computer-generated',\n",
       " 'feature cartoon',\n",
       " 'feature',\n",
       " 'cartoon',\n",
       " 'to feel like other movies',\n",
       " 'feel like other movies',\n",
       " 'feel',\n",
       " 'like other movies',\n",
       " 'other movies',\n",
       " 'other',\n",
       " 'that makes for some glacial pacing early on',\n",
       " 'makes for some glacial pacing early on',\n",
       " 'makes for some glacial pacing',\n",
       " 'makes',\n",
       " 'for some glacial pacing',\n",
       " 'some glacial pacing',\n",
       " 'glacial pacing',\n",
       " 'glacial',\n",
       " 'pacing',\n",
       " 'early on',\n",
       " 'early',\n",
       " \"There 's very little sense to what 's going on here , but the makers serve up the cliches with considerable dash .\",\n",
       " \"There 's very little sense to what 's going on here , but the makers serve up the cliches with considerable dash\",\n",
       " \"There 's very little sense to what 's going on here , but\",\n",
       " \"There 's very little sense to what 's going on here ,\",\n",
       " \"There 's very little sense to what 's going on here\",\n",
       " \"'s very little sense to what 's going on here\",\n",
       " \"very little sense to what 's going on here\",\n",
       " 'very little sense',\n",
       " 'very little',\n",
       " \"to what 's going on here\",\n",
       " \"what 's going on here\",\n",
       " \"'s going on here\",\n",
       " 'going on here',\n",
       " 'going on',\n",
       " 'here',\n",
       " 'the makers serve up the cliches with considerable dash',\n",
       " 'the makers',\n",
       " 'makers',\n",
       " 'serve up the cliches with considerable dash',\n",
       " 'serve up',\n",
       " 'serve',\n",
       " 'the cliches with considerable dash',\n",
       " 'the cliches',\n",
       " 'cliches',\n",
       " 'with considerable dash',\n",
       " 'considerable dash',\n",
       " 'considerable',\n",
       " 'dash',\n",
       " 'Cattaneo should have followed the runaway success of his first film , The Full Monty , with something different .',\n",
       " 'Cattaneo',\n",
       " 'should have followed the runaway success of his first film , The Full Monty , with something different .',\n",
       " 'should have followed the runaway success of his first film , The Full Monty , with something different',\n",
       " 'have followed the runaway success of his first film , The Full Monty , with something different',\n",
       " 'followed the runaway success of his first film , The Full Monty , with something different',\n",
       " 'followed the runaway success of his first film , The Full Monty ,',\n",
       " 'followed',\n",
       " 'the runaway success of his first film , The Full Monty ,',\n",
       " 'the runaway success',\n",
       " 'runaway success',\n",
       " 'runaway',\n",
       " 'success',\n",
       " 'of his first film , The Full Monty ,',\n",
       " 'his first film , The Full Monty ,',\n",
       " 'his first film , The Full Monty',\n",
       " 'his first film ,',\n",
       " 'his first film',\n",
       " 'first film',\n",
       " 'The Full Monty',\n",
       " 'Full Monty',\n",
       " 'Full',\n",
       " 'Monty',\n",
       " 'with something different',\n",
       " 'something different',\n",
       " 'different',\n",
       " \"They 're the unnamed , easily substitutable forces that serve as whatever terror the heroes of horror movies try to avoid .\",\n",
       " 'They',\n",
       " \"'re the unnamed , easily substitutable forces that serve as whatever terror the heroes of horror movies try to avoid .\",\n",
       " \"'re the unnamed , easily substitutable forces that serve as whatever terror the heroes of horror movies try to avoid\",\n",
       " \"'re\",\n",
       " 'the unnamed , easily substitutable forces that serve as whatever terror the heroes of horror movies try to avoid',\n",
       " 'the unnamed , easily substitutable forces',\n",
       " 'unnamed , easily substitutable forces',\n",
       " 'unnamed , easily substitutable',\n",
       " 'unnamed',\n",
       " ', easily substitutable',\n",
       " 'easily substitutable',\n",
       " 'easily',\n",
       " 'substitutable',\n",
       " 'forces',\n",
       " 'that serve as whatever terror the heroes of horror movies try to avoid',\n",
       " 'serve as whatever terror the heroes of horror movies try to avoid',\n",
       " 'as whatever terror the heroes of horror movies try to avoid',\n",
       " 'whatever terror the heroes of horror movies try to avoid',\n",
       " 'whatever',\n",
       " 'terror the heroes of horror movies try to avoid',\n",
       " 'terror',\n",
       " 'the heroes of horror movies try to avoid',\n",
       " 'the heroes of horror movies',\n",
       " 'the heroes',\n",
       " 'heroes',\n",
       " 'of horror movies',\n",
       " 'horror movies',\n",
       " 'horror',\n",
       " 'try to avoid',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in train['Phrase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose', 'is', 'also', 'good', 'for', 'the', 'gander', ',', 'some', 'of', 'which', 'occasionally', 'amuses', 'but', 'none', 'of', 'which', 'amounts', 'to', 'much', 'of', 'a', 'story', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(train['Phrase'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f2d50928208>>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenize)\n",
    "full_text = list(train['Phrase'].values) + list(test['Phrase'].values)\n",
    "tfidf.fit(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = tfidf.transform((train['Phrase']))\n",
    "test_features = tfidf.transform((test['Phrase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0)\n",
    "model = OneVsRestClassifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.34 s, sys: 108 ms, total: 9.45 s\n",
      "Wall time: 4.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_features, train['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean accuracy 56.55%, std 0.07.\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, train_features, train['Sentiment'],\\\n",
    "                         scoring='accuracy', n_jobs=-1, cv=3)\n",
    "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_Logis = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Sentiment'] = predicted_Logis\n",
    "sub.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keanu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk = Tokenizer(lower = True, filters='')\n",
    "tk.fit_on_texts(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tokenized = tk.texts_to_sequences(train['Phrase'])\n",
    "test_tokenized = tk.texts_to_sequences(test['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
    "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_path = \"../crawl-300d-2M.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "max_features = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
    "\n",
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_ohe = ohe.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = \"best_model.hdf5\"\n",
    "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                              save_best_only = True, mode = \"min\")\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
    "\n",
    "def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
    "    inp = Input(shape = (max_len,))\n",
    "    x = Embedding(19479, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    x1 = SpatialDropout1D(dr)(x)\n",
    "\n",
    "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
    "    x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool3_gru = GlobalAveragePooling1D()(x3)\n",
    "    max_pool3_gru = GlobalMaxPooling1D()(x3)\n",
    "    \n",
    "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
    "    x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_lstm = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool3_lstm = GlobalAveragePooling1D()(x3)\n",
    "    max_pool3_lstm = GlobalMaxPooling1D()(x3)\n",
    "    \n",
    "    \n",
    "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru,\n",
    "                    avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1)(Dense(128,activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1)(Dense(64,activation='relu') (x))\n",
    "    x = Dense(5, activation = \"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
    "    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 1, validation_split=0.1, \n",
    "                        verbose = 1, callbacks = [check_point, early_stop])\n",
    "    model = load_model(file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model(lr = 1e-3, lr_d = 0, units = 128, dr = 0.5)\n",
    "#Can't run on my computer since I don't have a GPU for tensorflow\n",
    "#Used Kaggle instead to run this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred2=model2.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.Sentiment=y_pred2\n",
    "sub.to_csv('sub2.csv',index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
